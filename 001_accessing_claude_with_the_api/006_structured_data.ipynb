{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a68ca0",
   "metadata": {},
   "source": [
    "# Structured Data\n",
    "\n",
    "Often, when you are using Claude to generate structured data (e.g., code, CSV, or a bulleted list of text), Claude prepends and appends commentary. For example, if you ask Claude to generate JSON for KRP's current stock price, you may get any output like the following.\n",
    "\n",
    "```text\n",
    "Based on the search results, here's the JSON for KRP's (Kimbell Royalty Partners) current stock price:\n",
    "```\n",
    "```json\n",
    "json{\n",
    "  \"ticker\": \"KRP\",\n",
    "  \"company_name\": \"Kimbell Royalty Partners, LP\",\n",
    "  \"current_price\": 11.50,\n",
    "  \"currency\": \"USD\",\n",
    "  \"price_change\": -0.29,\n",
    "  \"price_change_percent\": -2.46,\n",
    "  \"previous_close\": 12.28,\n",
    "  \"open\": 12.29,\n",
    "  \"day_range\": {\n",
    "    \"low\": 11.36,\n",
    "    \"high\": 11.79\n",
    "  },\n",
    "  \"52_week_range\": {\n",
    "    \"low\": 10.98,\n",
    "    \"high\": 16.59\n",
    "  },\n",
    "  \"volume\": 1214520,\n",
    "  \"average_volume\": 480609,\n",
    "  \"market_cap\": 1272000000,\n",
    "  \"dividend_yield\": 13.57,\n",
    "  \"pe_ratio\": null,\n",
    "  \"eps\": -0.09,\n",
    "  \"as_of_date\": \"2026-01-03\",\n",
    "  \"exchange\": \"NYSE\"\n",
    "}\n",
    "```\n",
    "```text\n",
    "The stock closed at $11.50, down $0.29 or 2.46% CNN from the previous close.\n",
    "```\n",
    "\n",
    "There may be situations where you'd like Claude to only produce the JSON (and omit the commentary). To encourage Claude to only provide the JSON, we can use **prefilled assistant messages** in combination with **stop sequences** (as initially discussed in `005_controlling_output.ipynb`).\n",
    "\n",
    "**Note:** The example above was copied from a real response from [claude.ai](https://claude.ai/). In this response, the price data is wrong, which is a good reminder of the limitations of contemporary LLMs. For this coding example, however, the accuracy of the information is not relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80191fd",
   "metadata": {},
   "source": [
    "## Set up the Environment and Create Helper Functions\n",
    "\n",
    "**Note:** For this example, which relies on asking Claude to do a bit more research, we are using `claude-sonnet-4-5`, which is more powerful than the `claude-sonnet-4-0` model we've used in other examples.\n",
    "\n",
    "**Note:** The `chat` function accepts stop sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d53aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and create client\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()   # Load environment variables from .env file\n",
    "\n",
    "# Create an API client\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d046f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions for managing message history and chatting with Claude\n",
    "\n",
    "def add_user_message(messages : list[str], content : str):\n",
    "    \"\"\"Append a user message to a message (aka conversation) history.\n",
    "\n",
    "    Args:\n",
    "        messages (list[str]): The message history.\n",
    "        content (str): A user message to append to the message history.\n",
    "    \"\"\"\n",
    "    user_message = { \"role\": \"user\", \"content\": content }\n",
    "    messages.append(user_message)\n",
    "\n",
    "def add_assistant_message(messages : list[str], content : str):\n",
    "    \"\"\"Append an assistant message to a message (aka conversation) history.\n",
    "\n",
    "    Args:\n",
    "        messages (list[str]): The message history.\n",
    "        content (str): An assistant message to append to the message history.\n",
    "    \"\"\"\n",
    "    assistant_message = { \"role\": \"assistant\", \"content\": content }\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "def chat(messages : list[str], stop_sequences: list[str] = []) -> str:\n",
    "    \"\"\"Chat with Claude.\n",
    "\n",
    "    Args:\n",
    "        messages (list[str]): The message (aka conversation) history.\n",
    "        stop_sequences (list[str], optional): Stop sequences for Claude's response. Defaults to [].\n",
    "\n",
    "    Returns:\n",
    "        str: Claude's text response.\n",
    "    \"\"\"\n",
    "    response = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1000,\n",
    "        messages=messages,\n",
    "        system=\"Provide concise answers.\",\n",
    "        stop_sequences=stop_sequences\n",
    "    )\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca0764",
   "metadata": {},
   "source": [
    "## Chat with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251064b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'symbol': 'KRP',\n",
       " 'company_name': 'Kimbell Royalty Partners, LP',\n",
       " 'current_price': None,\n",
       " 'currency': 'USD',\n",
       " 'last_updated': None,\n",
       " 'note': \"I don't have access to real-time stock market data. Please use a financial data service like Yahoo Finance, Bloomberg, Google Finance, or your brokerage platform to get the current stock price for KRP.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json     # For pretty-printing JSON output\n",
    "\n",
    "messages = []\n",
    "\n",
    "# Make is so Claude is biased towards Python as the best programming language for beginners\n",
    "add_user_message(messages, \"Generate JSON for KRP's current stock price.\")\n",
    "add_assistant_message(messages, \"```json\")\n",
    "\n",
    "response = chat(messages, stop_sequences=[\"```\"])\n",
    "json.loads(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c068e",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "In this exercise, you will use message prefilling and stop sequences *only* to get three different commands in a single response. There shouldn't be any comments or explanation. You will use the exact prompt listed below.\n",
    "\n",
    "**Hint:** message prefilling isn't limited to just characters like ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1a3f1",
   "metadata": {},
   "source": [
    "### Baseline Output (Raw Text and Markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d6cbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sample AWS CLI Commands\n",
      "\n",
      "Here are three short AWS CLI commands:\n",
      "\n",
      "## 1. List S3 Buckets\n",
      "```bash\n",
      "aws s3 ls\n",
      "```\n",
      "\n",
      "## 2. Describe EC2 Instances\n",
      "```bash\n",
      "aws ec2 describe-instances\n",
      "```\n",
      "\n",
      "## 3. List IAM Users\n",
      "```bash\n",
      "aws iam list-users\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Sample AWS CLI Commands\n",
       "\n",
       "Here are three short AWS CLI commands:\n",
       "\n",
       "## 1. List S3 Buckets\n",
       "```bash\n",
       "aws s3 ls\n",
       "```\n",
       "\n",
       "## 2. Describe EC2 Instances\n",
       "```bash\n",
       "aws ec2 describe-instances\n",
       "```\n",
       "\n",
       "## 3. List IAM Users\n",
       "```bash\n",
       "aws iam list-users\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline output\n",
    "\n",
    "from IPython.display import Markdown    # For pretty-printing Markdown output\n",
    "\n",
    "messages = []\n",
    "\n",
    "prompt = \"Generate three different sample AWS CLI commands. Each command should be short.\"\n",
    "\n",
    "add_user_message(messages, prompt)\n",
    "response = chat(messages)\n",
    "\n",
    "print(response)\n",
    "\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2e20d",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d59bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "aws s3 ls s3://my-bucket/\n",
      "\n",
      "aws ec2 describe-instances --instance-ids i-1234567890abcdef0\n",
      "\n",
      "aws lambda invoke --function-name my-function output.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "prompt = \"Generate three different sample AWS CLI commands. Each command should be short.\"\n",
    "\n",
    "add_user_message(messages, prompt)\n",
    "add_assistant_message(messages, \"Here are all three commands without any comments:\\n```bash\")\n",
    "response = chat(messages, stop_sequences=[\"```\"])\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209750a7",
   "metadata": {},
   "source": [
    "# Streaming Responses\n",
    "A notebook that demonstrates how to steam Claude output (responses) to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab53689",
   "metadata": {},
   "source": [
    "## Set up the Environment and Create Helper Functions\n",
    "**Note:** When compared to previous notebooks, the `chat` helper function has moved out of the helper section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d53aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and create client\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()   # Load environment variables from .env file\n",
    "\n",
    "# Create an API client\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d046f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions for managing message history and chatting with Claude\n",
    "\n",
    "def add_user_message(messages : list[str], content : str):\n",
    "    \"\"\"Append a user message to a message (aka conversation) history.\n",
    "\n",
    "    Args:\n",
    "        messages (list[str]): The message history.\n",
    "        content (str): A user message to append to the message history.\n",
    "    \"\"\"\n",
    "    user_message = { \"role\": \"user\", \"content\": content }\n",
    "    messages.append(user_message)\n",
    "\n",
    "def add_assistant_message(messages : list[str], content : str):\n",
    "    \"\"\"Append an assistant message to a message (aka conversation) history.\n",
    "\n",
    "    Args:\n",
    "        messages (list[str]): The message history.\n",
    "        content (str): An assistant message to append to the message history.\n",
    "    \"\"\"\n",
    "    assistant_message = { \"role\": \"assistant\", \"content\": content }\n",
    "    messages.append(assistant_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51bdbc9",
   "metadata": {},
   "source": [
    "## Chat with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251064b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamed response:\n",
      "Romeo and Juliet, two young lovers from feuding families in Verona, secretly marry but ultimately die by suicide due to miscommunication and their families' hatred, which finally reconciles the warring houses.\n",
      "\n",
      "Final response:\n",
      "Romeo and Juliet, two young lovers from feuding families in Verona, secretly marry but ultimately die by suicide due to miscommunication and their families' hatred, which finally reconciles the warring houses.\n",
      "\n",
      "Final message:\n",
      "Message(id='msg_014sNKWFrakgN6d7iJEYuc3s', content=[TextBlock(citations=None, text=\"Romeo and Juliet, two young lovers from feuding families in Verona, secretly marry but ultimately die by suicide due to miscommunication and their families' hatred, which finally reconciles the warring houses.\", type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation=CacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=23, output_tokens=48, server_tool_use=None, service_tier='standard'))\n"
     ]
    }
   ],
   "source": [
    "# Chat with Claude\n",
    "\n",
    "# create a messages list to hold the conversation history\n",
    "messages = []\n",
    "\n",
    "add_user_message(messages, \"Write me a one sentence summary of the plot of Romeo and Juliet.\")\n",
    "\n",
    "# Streaming response from Claude\n",
    "with client.messages.stream(\n",
    "    model=model,\n",
    "    max_tokens=1000,\n",
    "    messages=messages,\n",
    ") as stream:\n",
    "    print(\"Streamed response:\")\n",
    "    for text in stream.text_stream:\n",
    "        print(text, end=\"\")             # the end=\"\" parameter prevents newlines after each print command\n",
    "    print()                             # Print a newline after the streamed response is complete\n",
    "\n",
    "# Get the final text (to, for example, store in the chat history)\n",
    "print(\"\\nFinal response:\")\n",
    "response = stream.get_final_text()\n",
    "add_assistant_message(messages, response)\n",
    "print(response)\n",
    "\n",
    "# Get the final message object (to, for example, store in a database), if needed\n",
    "print(\"\\nFinal message:\")\n",
    "final_message = stream.get_final_message()\n",
    "print(final_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
